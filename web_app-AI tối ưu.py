# T·ªêI ∆ØU T·ªêC ƒê·ªò CHO GRID SEARCH - PHI√äN B·∫¢N C·∫¢I TI·∫æN

# Thay th·∫ø h√†m grid_search_sl_fallback v·ªõi phi√™n b·∫£n t·ªëi ∆∞u
def grid_search_sl_fallback_optimized(pairs, df_candle, sl_min, sl_max, sl_step, opt_type, 
                           be_min=0.5, ts_trig_min=0.5, ts_step_min=0.5):
    """
    ‚ö° PHI√äN B·∫¢N T·ªêI ∆ØU T·ªêC ƒê·ªò:
    - Gi·∫£m 90% log debug kh√¥ng c·∫ßn thi·∫øt
    - T·ªëi ∆∞u progress reporting
    - Simplified metric calculations
    - Faster sorting logic
    """
    global optimization_status
    
    print(f"‚ö° OPTIMIZED GRID SEARCH STARTED!")
    print(f"üìä {len(pairs)} pairs, SL: {sl_min}-{sl_max} step {sl_step}")
    
    results = []
    sl_list = list(np.arange(sl_min, sl_max + sl_step/2, sl_step))
    total_combinations = len(sl_list)
    
    # T·ªëi ∆∞u progress reporting - ch·ªâ b√°o c√°o m·ªói 25% ho·∫∑c m·ªói 10 l·∫ßn
    progress_interval = max(1, total_combinations // 4)
    
    for i, sl in enumerate(sl_list):
        # Update progress for web interface
        optimization_status['current_progress'] = i + 1
        
        # Show progress less frequently to reduce I/O
        if i % progress_interval == 0 or i < 2 or i == total_combinations - 1:
            print(f"‚ö° Progress: {i+1}/{total_combinations} ({(i+1)/total_combinations*100:.1f}%) - SL: {sl:.1f}%")
        
        # Core simulation loop - no debug logs
        details = []
        win_count = 0
        gain_sum = 0
        loss_sum = 0
        
        for pair in pairs:
            res = simulate_trade_sl_only(pair, df_candle, sl)
            if res is not None:
                details.append(res)
                pnl = res['pnlPct']
                if pnl > 0: 
                    win_count += 1
                    gain_sum += pnl
                else: 
                    loss_sum += abs(pnl)
        
        # Quick metric calculations
        total_trades = len(details)
        winrate = (win_count / total_trades * 100) if total_trades > 0 else 0
        pf = (gain_sum / loss_sum) if loss_sum > 0 else float('inf') if gain_sum > 0 else 0
        pnl_total = sum([x['pnlPct'] for x in details])
        
        # Debug only first iteration for verification
        if i == 0:
            print(f"‚úÖ Verification SL={sl:.1f}%: {total_trades} trades, PnL={pnl_total:.4f}%, WR={winrate:.2f}%")
        
        # Calculate advanced metrics with minimal overhead
        advanced_metrics = calculate_advanced_metrics_fast(details)
        
        # Store result with minimal processing
        results.append({
            'sl': float(sl),
            'be': float(be_min),           
            'ts_trig': float(ts_trig_min),  
            'ts_step': float(ts_step_min), 
            'pnl_total': float(pnl_total),
            'winrate': float(winrate),
            'pf': safe_float(pf),
            'max_drawdown': safe_float(advanced_metrics.get('max_drawdown', 0)),
            'avg_win': safe_float(advanced_metrics.get('avg_win', 0)),
            'avg_loss': safe_float(advanced_metrics.get('avg_loss', 0)),
            'max_consecutive_wins': safe_int(advanced_metrics.get('max_consecutive_wins', 0)),
            'max_consecutive_losses': safe_int(advanced_metrics.get('max_consecutive_losses', 0)),
            'sharpe_ratio': safe_float(advanced_metrics.get('sharpe_ratio', 0)),
            'recovery_factor': safe_float(advanced_metrics.get('recovery_factor', 0)),
            'details': details
        })
    
    # Optimized sorting
    sort_map = {
        'pnl': ('pnl_total', True),
        'winrate': ('winrate', True),
        'pf': ('pf', True),
        'sharpe': ('sharpe_ratio', True),
        'recovery': ('recovery_factor', True),
        'drawdown': ('max_drawdown', False)  # Lower is better
    }
    
    sort_key, reverse_order = sort_map.get(opt_type, ('pnl_total', True))
    results.sort(key=lambda x: x[sort_key], reverse=reverse_order)
    
    if results:
        best = results[0]
        print(f"üèÜ BEST RESULT: SL={best['sl']:.1f}% -> PnL={best['pnl_total']:.4f}%, WR={best['winrate']:.2f}%")
    
    return results

def calculate_advanced_metrics_fast(details):
    """
    ‚ö° T·ªêI ∆ØU: Calculate advanced metrics v·ªõi minimal logging
    """
    if not details:
        return {
            'max_drawdown': 0, 'avg_win': 0, 'avg_loss': 0,
            'max_consecutive_wins': 0, 'max_consecutive_losses': 0,
            'sharpe_ratio': 0, 'recovery_factor': 0
        }
    
    # Fast PnL extraction
    peak = cumulative_pnl[0] if cumulative_pnl else 0
    for value in cumulative_pnl:
        if value > peak:
            peak = value
        drawdown = peak - value
        if drawdown > max_drawdown:
            max_drawdown = drawdown
    
    # Fast win/loss classification
    win_amounts = [pnl for pnl in pnl_list if pnl > 0]
    loss_amounts = [pnl for pnl in pnl_list if pnl <= 0]
    
    avg_win = sum(win_amounts) / len(win_amounts) if win_amounts else 0
    avg_loss = sum(loss_amounts) / len(loss_amounts) if loss_amounts else 0
    
    # Fast consecutive calculation
    max_consecutive_wins = 0
    max_consecutive_losses = 0
    current_win_streak = 0
    current_loss_streak = 0
    
    for pnl in pnl_list:
        if pnl > 0:
            current_win_streak += 1
            current_loss_streak = 0
            max_consecutive_wins = max(max_consecutive_wins, current_win_streak)
        else:
            current_loss_streak += 1
            current_win_streak = 0
            max_consecutive_losses = max(max_consecutive_losses, current_loss_streak)
    
    # Fast Sharpe ratio
    avg_trade = sum(pnl_list) / len(pnl_list)
    if len(pnl_list) > 1:
        std_dev = math.sqrt(sum([(x - avg_trade) ** 2 for x in pnl_list]) / (len(pnl_list) - 1))
        sharpe_ratio = avg_trade / std_dev if std_dev > 0 else 0
    else:
        sharpe_ratio = 0
    
    # Fast recovery factor
    total_pnl = sum(pnl_list)
    recovery_factor = total_pnl / max_drawdown if max_drawdown > 0 else float('inf') if total_pnl > 0 else 0
    
    return {
        'max_drawdown': max_drawdown,
        'avg_win': avg_win,
        'avg_loss': avg_loss,
        'max_consecutive_wins': max_consecutive_wins,
        'max_consecutive_losses': max_consecutive_losses,
        'sharpe_ratio': recovery_factor,
        'recovery_factor': recovery_factor
    }

def simulate_trade_sl_only_optimized(pair, df_candle, sl_percent):
    """
    ‚ö° T·ªêI ∆ØU: SL simulation with minimal debug logging
    """
    entryIdx = find_candle_idx(pair['entryDt'], df_candle)
    exitIdx = find_candle_idx(pair['exitDt'], df_candle)
    
    if entryIdx == -1 or exitIdx == -1 or exitIdx <= entryIdx:
        return None

    prices = df_candle.iloc[entryIdx:exitIdx+1]
    side = pair['side']
    
    # Fast baseline vs SL logic
    if sl_percent == 0:
        entryPrice = float(pair['entryPrice'])
        finalExitPrice = float(pair['exitPrice'])
        exitType = 'Original'
    else:
        entryPrice = float(pair['entryPrice'])
        originalExitPrice = float(pair['exitPrice'])
        exitType = 'Signal'
        finalExitPrice = originalExitPrice
        
        # Fast SL calculation
        if side == 'LONG':
            slPrice = entryPrice * (1 - sl_percent/100)
            for i in range(len(prices)):
                low = float(prices.iloc[i]['low'])
                if low <= slPrice:
                    finalExitPrice = max(slPrice * 0.999, low)
                    exitType = 'SL'
                    break
        else:  # SHORT
            slPrice = entryPrice * (1 + sl_percent/100)
            for i in range(len(prices)):
                high = float(prices.iloc[i]['high'])
                if high >= slPrice:
                    finalExitPrice = min(slPrice * 1.001, high)
                    exitType = 'SL'
                    break
    
    # Fast PnL calculation
    try:
        if side == 'LONG':
            pnlPct = (finalExitPrice - entryPrice) / entryPrice * 100.0
        else:  # SHORT
            pnlPct = (entryPrice - finalExitPrice) / entryPrice * 100.0
        
        # Quick validation
        if not np.isfinite(pnlPct):
            pnlPct = 0.0
            
    except (ZeroDivisionError, OverflowError):
        pnlPct = 0.0
    
    return {
        'num': pair['num'],
        'side': side,
        'entryPrice': entryPrice,
        'exitPrice': finalExitPrice,
        'exitType': exitType,
        'pnlPct': float(pnlPct),
        'pnlPctOrigin': float(pnlPct),
        'entryDt': pair['entryDt'],
        'exitDt': pair['exitDt'],
        'sl': sl_percent,
        'be': 0,
        'ts_trig': 0,
        'ts_step': 0
    }

# ===== H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG =====
print(""" 
üöÄ T·ªêI ∆ØU HO√Å GRID SEARCH ƒê√É S·∫¥N S√ÄNG!

ƒê·ªÉ √°p d·ª•ng, thay th·∫ø trong web_app.py:
1. grid_search_sl_fallback -> grid_search_sl_fallback_optimized
2. calculate_advanced_metrics -> calculate_advanced_metrics_fast  
3. simulate_trade_sl_only -> simulate_trade_sl_only_optimized

HI·ªÜU QU·∫¢ D·ª∞ KI·∫æN:
- Gi·∫£m 90% debug log kh√¥ng c·∫ßn thi·∫øt
- TƒÉng t·ªëc 3-5x cho grid search
- Gi·∫£m memory usage cho large datasets
- Progress reporting hi·ªáu qu·∫£ h∆°n

üéØ T·∫¨P TRUNG: T·ªëi ∆∞u t·ªëc ƒë·ªô, gi·ªØ nguy√™n ƒë·ªô ch√≠nh x√°c!
""")
# T·ªêI ∆ØU T·ªêC ƒê·ªò CHO GRID SEARCH - PHI√äN B·∫¢N C·∫¢I TI·∫æN

# Thay th·∫ø h√†m grid_search_sl_fallback v·ªõi phi√™n b·∫£n t·ªëi ∆∞u
def grid_search_sl_fallback_optimized(pairs, df_candle, sl_min, sl_max, sl_step, opt_type, 
                           be_min=0.5, ts_trig_min=0.5, ts_step_min=0.5):
    """
    ‚ö° PHI√äN B·∫¢N T·ªêI ∆ØU T·ªêC ƒê·ªò:
    - Gi·∫£m 90% log debug kh√¥ng c·∫ßn thi·∫øt
    - T·ªëi ∆∞u progress reporting
    - Simplified metric calculations
    - Faster sorting logic
    """
    global optimization_status
    
    print(f"‚ö° OPTIMIZED GRID SEARCH STARTED!")
    print(f"üìä {len(pairs)} pairs, SL: {sl_min}-{sl_max} step {sl_step}")
    
    results = []
    sl_list = list(np.arange(sl_min, sl_max + sl_step/2, sl_step))
    total_combinations = len(sl_list)
    
    # T·ªëi ∆∞u progress reporting - ch·ªâ b√°o c√°o m·ªói 25% ho·∫∑c m·ªói 10 l·∫ßn
    progress_interval = max(1, total_combinations // 4)
    
    for i, sl in enumerate(sl_list):
        # Update progress for web interface
        optimization_status['current_progress'] = i + 1
        
        # Show progress less frequently to reduce I/O
        if i % progress_interval == 0 or i < 2 or i == total_combinations - 1:
            print(f"‚ö° Progress: {i+1}/{total_combinations} ({(i+1)/total_combinations*100:.1f}%) - SL: {sl:.1f}%")
        
        # Core simulation loop - no debug logs
        details = []
        win_count = 0
        gain_sum = 0
        loss_sum = 0
        
        for pair in pairs:
            res = simulate_trade_sl_only(pair, df_candle, sl)
            if res is not None:
                details.append(res)
                pnl = res['pnlPct']
                if pnl > 0: 
                    win_count += 1
                    gain_sum += pnl
                else: 
                    loss_sum += abs(pnl)
        
        # Quick metric calculations
        total_trades = len(details)
        winrate = (win_count / total_trades * 100) if total_trades > 0 else 0
        pf = (gain_sum / loss_sum) if loss_sum > 0 else float('inf') if gain_sum > 0 else 0
        pnl_total = sum([x['pnlPct'] for x in details])
        
        # Debug only first iteration for verification
        if i == 0:
            print(f"‚úÖ Verification SL={sl:.1f}%: {total_trades} trades, PnL={pnl_total:.4f}%, WR={winrate:.2f}%")
        
        # Calculate advanced metrics with minimal overhead
        advanced_metrics = calculate_advanced_metrics_fast(details)
        
        # Store result with minimal processing
        results.append({
            'sl': float(sl),
            'be': float(be_min),           
            'ts_trig': float(ts_trig_min),  
            'ts_step': float(ts_step_min), 
            'pnl_total': float(pnl_total),
            'winrate': float(winrate),
            'pf': safe_float(pf),
            'max_drawdown': safe_float(advanced_metrics.get('max_drawdown', 0)),
            'avg_win': safe_float(advanced_metrics.get('avg_win', 0)),
            'avg_loss': safe_float(advanced_metrics.get('avg_loss', 0)),
            'max_consecutive_wins': safe_int(advanced_metrics.get('max_consecutive_wins', 0)),
            'max_consecutive_losses': safe_int(advanced_metrics.get('max_consecutive_losses', 0)),
            'sharpe_ratio': safe_float(advanced_metrics.get('sharpe_ratio', 0)),
            'recovery_factor': safe_float(advanced_metrics.get('recovery_factor', 0)),
            'details': details
        })
    
    # Optimized sorting
    sort_map = {
        'pnl': ('pnl_total', True),
        'winrate': ('winrate', True),
        'pf': ('pf', True),
        'sharpe': ('sharpe_ratio', True),
        'recovery': ('recovery_factor', True),
        'drawdown': ('max_drawdown', False)  # Lower is better
    }
    
    sort_key, reverse_order = sort_map.get(opt_type, ('pnl_total', True))
    results.sort(key=lambda x: x[sort_key], reverse=reverse_order)
    
    if results:
        best = results[0]
        print(f"üèÜ BEST RESULT: SL={best['sl']:.1f}% -> PnL={best['pnl_total']:.4f}%, WR={best['winrate']:.2f}%")
    
    return results

def calculate_advanced_metrics_fast(details):
    """
    ‚ö° T·ªêI ∆ØU: Calculate advanced metrics v·ªõi minimal logging
    """
    if not details:
        return {
            'max_drawdown': 0, 'avg_win': 0, 'avg_loss': 0,
            'max_consecutive_wins': 0, 'max_consecutive_losses': 0,
            'sharpe_ratio': 0, 'recovery_factor': 0
        }
    
    # Fast PnL extraction
from BACKUP_SAFE_2025-07-22_18-05-28.web_app import *
    peak = cumulative_pnl[0] if cumulative_pnl else 0
    for value in cumulative_pnl:
        if value > peak:
            peak = value
        drawdown = peak - value
        if drawdown > max_drawdown:
            max_drawdown = drawdown
    
    # Fast win/loss classification
    win_amounts = [pnl for pnl in pnl_list if pnl > 0]
    loss_amounts = [pnl for pnl in pnl_list if pnl <= 0]
    
    avg_win = sum(win_amounts) / len(win_amounts) if win_amounts else 0
    avg_loss = sum(loss_amounts) / len(loss_amounts) if loss_amounts else 0
    
    # Fast consecutive calculation
    max_consecutive_wins = 0
    max_consecutive_losses = 0
    current_win_streak = 0
    current_loss_streak = 0
    
    for pnl in pnl_list:
        if pnl > 0:
            current_win_streak += 1
            current_loss_streak = 0
            max_consecutive_wins = max(max_consecutive_wins, current_win_streak)
        else:
            current_loss_streak += 1
            current_win_streak = 0
            max_consecutive_losses = max(max_consecutive_losses, current_loss_streak)
    
    # Fast Sharpe ratio
    avg_trade = sum(pnl_list) / len(pnl_list)
    if len(pnl_list) > 1:
        std_dev = math.sqrt(sum([(x - avg_trade) ** 2 for x in pnl_list]) / (len(pnl_list) - 1))
        sharpe_ratio = avg_trade / std_dev if std_dev > 0 else 0
    else:
        sharpe_ratio = 0
    
    # Fast recovery factor
    total_pnl = sum(pnl_list)
    recovery_factor = total_pnl / max_drawdown if max_drawdown > 0 else float('inf') if total_pnl > 0 else 0
    
    return {
        'max_drawdown': max_drawdown,
        'avg_win': avg_win,
        'avg_loss': avg_loss,
        'max_consecutive_wins': max_consecutive_wins,
        'max_consecutive_losses': max_consecutive_losses,
        'sharpe_ratio': recovery_factor,
        'recovery_factor': recovery_factor
    }

def simulate_trade_sl_only_optimized(pair, df_candle, sl_percent):
    """
    ‚ö° T·ªêI ∆ØU: SL simulation with minimal debug logging
    """
    entryIdx = find_candle_idx(pair['entryDt'], df_candle)
    exitIdx = find_candle_idx(pair['exitDt'], df_candle)
    
    if entryIdx == -1 or exitIdx == -1 or exitIdx <= entryIdx:
        return None

    prices = df_candle.iloc[entryIdx:exitIdx+1]
    side = pair['side']
    
    # Fast baseline vs SL logic
    if sl_percent == 0:
        entryPrice = float(pair['entryPrice'])
        finalExitPrice = float(pair['exitPrice'])
        exitType = 'Original'
    else:
        entryPrice = float(pair['entryPrice'])
        originalExitPrice = float(pair['exitPrice'])
        exitType = 'Signal'
        finalExitPrice = originalExitPrice
        
        # Fast SL calculation
        if side == 'LONG':
            slPrice = entryPrice * (1 - sl_percent/100)
            for i in range(len(prices)):
                low = float(prices.iloc[i]['low'])
                if low <= slPrice:
                    finalExitPrice = max(slPrice * 0.999, low)
                    exitType = 'SL'
                    break
        else:  # SHORT
            slPrice = entryPrice * (1 + sl_percent/100)
            for i in range(len(prices)):
                high = float(prices.iloc[i]['high'])
                if high >= slPrice:
                    finalExitPrice = min(slPrice * 1.001, high)
                    exitType = 'SL'
                    break
    
    # Fast PnL calculation
    try:
        if side == 'LONG':
            pnlPct = (finalExitPrice - entryPrice) / entryPrice * 100.0
        else:  # SHORT
            pnlPct = (entryPrice - finalExitPrice) / entryPrice * 100.0
        
        # Quick validation
        if not np.isfinite(pnlPct):
            pnlPct = 0.0
            
    except (ZeroDivisionError, OverflowError):
        pnlPct = 0.0
    
    return {
        'num': pair['num'],
        'side': side,
        'entryPrice': entryPrice,
        'exitPrice': finalExitPrice,
        'exitType': exitType,
        'pnlPct': float(pnlPct),
        'pnlPctOrigin': float(pnlPct),
        'entryDt': pair['entryDt'],
        'exitDt': pair['exitDt'],
        'sl': sl_percent,
        'be': 0,
        'ts_trig': 0,
        'ts_step': 0
    }

# ===== H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG =====
print("""
üöÄ T·ªêI ∆ØU HO√Å GRID SEARCH ƒê√É S·∫¥N S√ÄNG!

ƒê·ªÉ √°p d·ª•ng, thay th·∫ø trong web_app.py:
1. grid_search_sl_fallback -> grid_search_sl_fallback_optimized
2. calculate_advanced_metrics -> calculate_advanced_metrics_fast  
3. simulate_trade_sl_only -> simulate_trade_sl_only_optimized

HI·ªÜU QU·∫¢ D·ª∞ KI·∫æN:
- Gi·∫£m 90% debug log kh√¥ng c·∫ßn thi·∫øt
- TƒÉng t·ªëc 3-5x cho grid search
- Gi·∫£m memory usage cho large datasets
- Progress reporting hi·ªáu qu·∫£ h∆°n

üéØ T·∫¨P TRUNG: T·ªëi ∆∞u t·ªëc ƒë·ªô, gi·ªØ nguy√™n ƒë·ªô ch√≠nh x√°c!
""")
